# A-survey-on-Mamba
📄✅❗️0️⃣1️⃣2️⃣3️⃣4️⃣5️⃣6️⃣7️⃣8️⃣9️⃣
## Mamba
- Linear-Time Sequence Modeling with Selective State Spaces <br>
Paper Link: [📄📄📄](https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf), Code：[✅✅✅](https://github.com/state-spaces/mamba)


## Improvements and Optimizations Based on Mamba
- 0️⃣1️⃣ <br>
MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts <br>
Paper Link: [📄📄📄](https://arxiv.org/pdf/2401.04081.pdf), Code：[❗️❗️❗️] <br>
Summary: 这篇论文介绍了MambaByte，这是一种无需标记的、基于状态空间模型（SSM）的字节级语言模型，它通过自回归方式训练于字节序列上。MambaByte直接使用字节作为序列的基本单元。MambaByte在多个数据集上展示了与其他字节级模型相比的优越性能，并与最先进的基于子词的Transformer模型竞争，同时在推理速度上由于其线性扩展特性而受益。研究表明，MambaByte是一种有效的无需标记的语言建模方法，为未来的大型模型提供了一种可行的无需标记的语言建模可能性。

- 0️⃣2️⃣ <br>
MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts <br>
Paper Link: [📄📄📄](https://arxiv.org/pdf/2401.04081.pdf), Code：[❗️❗️❗️] <br>
Summary: 这篇论文介绍了MambaByte，这是一种无需标记的、基于状态空间模型（SSM）的字节级语言模型，它通过自回归方式训练于字节序列上。MambaByte直接使用字节作为序列的基本单元。MambaByte在多个数据集上展示了与其他字节级模型相比的优越性能，并与最先进的基于子词的Transformer模型竞争，同时在推理速度上由于其线性扩展特性而受益。研究表明，MambaByte是一种有效的无需标记的语言建模方法，为未来的大型模型提供了一种可行的无需标记的语言建模可能性。

## Vision Mamba

## Image Segmentation Based on Mamba

## Image or Video Generation Based on Mamba

## Image Dehazing Based on Mamba

## Point Cloud Processing Based on Mamba

## Graph Network Based on Mamba

## Other Applications Based on Mamba
